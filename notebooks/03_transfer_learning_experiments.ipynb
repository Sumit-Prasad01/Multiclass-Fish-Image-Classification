{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b35ed34b",
   "metadata": {},
   "source": [
    "## Transfer Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80e189a",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1f7dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.applications import MobileNetV2, ResNet50, EfficientNetB0,InceptionV3,VGG16\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f12154",
   "metadata": {},
   "source": [
    "## Declare Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e6efe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "CHANNELS = 3\n",
    "EPOCHS = 50\n",
    "input_shape = (BATCH_SIZE,IMAGE_SIZE,IMAGE_SIZE,CHANNELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db611510",
   "metadata": {},
   "source": [
    "## Load Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42c76aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../data/train\",\n",
    "    shuffle = True,\n",
    "    image_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "    batch_size = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5456fb70",
   "metadata": {},
   "source": [
    "## Load Test Datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df60e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../data/test\",\n",
    "    shuffle = True,\n",
    "    image_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "    batch_size = BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde5b32b",
   "metadata": {},
   "source": [
    "## Load Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1749b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../data/val\",\n",
    "    shuffle = True,\n",
    "    image_size = (IMAGE_SIZE,IMAGE_SIZE),\n",
    "    batch_size = BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c53b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names\n",
    "n_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4283c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bca8d28",
   "metadata": {},
   "source": [
    "## Prepare Datasets for Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c40df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "val_dataset = valid_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221dfcbc",
   "metadata": {},
   "source": [
    "## Load PreTrained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c5648",
   "metadata": {},
   "source": [
    "### The build_model function:\n",
    "\n",
    "- Loads a pre-trained CNN model (like MobileNet, ResNet, etc.) without the top classification layer (include_top=False).\n",
    "\n",
    "- Freezes the base modelâ€™s weights (no training).\n",
    "\n",
    "- Adds custom layers on top:\n",
    "\n",
    "    - GlobalAveragePooling2D\n",
    "\n",
    "    - Dropout (to reduce overfitting)\n",
    "\n",
    "    - Dense softmax output layer for classification.\n",
    "\n",
    "- Compiles the model with:\n",
    "\n",
    "    - adam optimizer\n",
    "\n",
    "    - sparse_categorical_crossentropy loss\n",
    "\n",
    "    - accuracy metric\n",
    "\n",
    "### Returns the final compiled model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81172ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (224, 224)\n",
    "def build_model(base_model_fn, model_name):\n",
    "    print(f\"\\nBuilding model: {model_name}\")\n",
    "    base_model = base_model_fn(\n",
    "        input_shape=IMAGE_SIZE + (3,),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = False  # Freeze base model\n",
    "\n",
    "    inputs = tf.keras.Input(shape=IMAGE_SIZE + (3,))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs, name=model_name)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97b7b7c",
   "metadata": {},
   "source": [
    "## List of Pretrained Models to Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4789581",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pretrained_models = {\n",
    "    \"MobileNetV2\": MobileNetV2,\n",
    "    \"ResNet50\": ResNet50,\n",
    "    \"EfficientNetB0\": EfficientNetB0, \n",
    "    \"InceptionV3\" : InceptionV3,\n",
    "    \"VGG16\" : VGG16\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678535d9",
   "metadata": {},
   "source": [
    "## Train Each Model and Collect Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae660fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = {}\n",
    "val_accuracies = {}\n",
    "\n",
    "for name, base_model_fn in pretrained_models.items():\n",
    "    model = build_model(base_model_fn, name)\n",
    "    \n",
    "    early_stop = EarlyStopping(patience=3, restore_best_weights=True)\n",
    "    \n",
    "    print(f\"Training {name}...\")\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=50,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    val_acc = max(history.history[\"val_accuracy\"])\n",
    "    val_accuracies[name] = val_acc\n",
    "    histories[name] = history\n",
    "    print(f\"{name} max val_accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8721aa86",
   "metadata": {},
   "source": [
    "## Get the best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa26c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model_name = max(val_accuracies, key=val_accuracies.get)\n",
    "print(f\"\\n Best model is: {best_model_name} with validation accuracy: {val_accuracies[best_model_name]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6e1b55",
   "metadata": {},
   "source": [
    "## Rebuild the Best Model (for test + fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c917df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(base_model_fn, model_name, trainable=False):\n",
    "    print(f\"\\nBuilding model: {model_name}\")\n",
    "    base_model = base_model_fn(\n",
    "        input_shape=IMAGE_SIZE + (3,),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = trainable  # Control trainable param\n",
    "\n",
    "    inputs = tf.keras.Input(shape=IMAGE_SIZE + (3,))\n",
    "    x = base_model(inputs, training=not trainable)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs, name=model_name)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b210c2",
   "metadata": {},
   "source": [
    "## Re-evaluate Best Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f129ab23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild best model (frozen)\n",
    "best_model = build_model(pretrained_models[best_model_name], best_model_name, trainable=False)\n",
    "\n",
    "# Train briefly (for consistent weights)\n",
    "best_model.fit(train_dataset, validation_data=val_dataset, epochs=5)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = best_model.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy (frozen): {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef76252c",
   "metadata": {},
   "source": [
    "## Fine-Tune the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d1bb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze top layers for fine-tuning\n",
    "fine_tune_at = 100\n",
    "\n",
    "base_model = best_model.layers[1]  # Get base model from sequential\n",
    "base_model.trainable = True\n",
    "\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile with low learning rate for fine-tuning\n",
    "best_model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "                   loss='sparse_categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune training\n",
    "fine_tune_history = best_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=5,\n",
    "    callbacks=[EarlyStopping(patience=2, restore_best_weights=True)]\n",
    ")\n",
    "\n",
    "# Final test accuracy\n",
    "test_loss_ft, test_acc_ft = best_model.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy (fine-tuned): {test_acc_ft:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d56fd0",
   "metadata": {},
   "source": [
    "## Compare Before & After Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2932bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Before fine-tuning test acc: {test_acc:.4f}\")\n",
    "print(f\"After fine-tuning  test acc: {test_acc_ft:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa4385a",
   "metadata": {},
   "source": [
    "## Extract metrics from fine-tuning history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fa4e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = fine_tune_history.history['accuracy']\n",
    "val_acc = fine_tune_history.history['val_accuracy']\n",
    "loss = fine_tune_history.history['loss']\n",
    "val_loss = fine_tune_history.history['val_loss']\n",
    "epochs_ran = len(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9715663c",
   "metadata": {},
   "source": [
    "## Accuracy and Validation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5461fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(epochs_ran), acc, label='Training Accuracy')\n",
    "plt.plot(range(epochs_ran), val_acc, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('../results/metrices/TransferLearning/Training_vs_Validation_Accuracy.png')\n",
    "\n",
    "# Loss Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(epochs_ran), loss, label='Training Loss')\n",
    "plt.plot(range(epochs_ran), val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig('../results/metrices/TransferLearning/Training_vs_Validation_Loss.png')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1b4705",
   "metadata": {},
   "source": [
    "## Making prediction on single image from test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf88625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Iterate through one batch from the test dataset\n",
    "for images_batch, labels_batch in test_dataset.take(1):\n",
    "    \n",
    "    # Extract first image and label\n",
    "    first_image = images_batch[0].numpy().astype('uint8')\n",
    "    first_label = labels_batch[0].numpy()\n",
    "    \n",
    "    # Show image\n",
    "    print(\"First image to predict:\")\n",
    "    plt.imshow(first_image)\n",
    "    plt.axis('off')  # Hide axis for cleaner display\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Actual label:\", class_names[first_label])\n",
    "\n",
    "    # Make prediction using fine-tuned best model\n",
    "    batch_prediction = best_model.predict(images_batch)\n",
    "    predicted_class = class_names[np.argmax(batch_prediction[0])]\n",
    "\n",
    "    print(\"Predicted label:\", predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b166ff84",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb0d4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, img):\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Add batch dimension\n",
    "\n",
    "    predictions = model.predict(img_array, verbose=0)\n",
    "    predicted_class = class_names[np.argmax(predictions[0])]\n",
    "    confidence = round(100 * np.max(predictions[0]), 2)\n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1752c3f6",
   "metadata": {},
   "source": [
    "## Display 9 images with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118406ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "for images, labels in test_dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        \n",
    "        predicted_class, confidence = predict(best_model, images[i])\n",
    "        actual_class = class_names[labels[i].numpy()]\n",
    "        \n",
    "        plt.title(f\"Actual: {actual_class}\\nPredicted: {predicted_class}\\nConfidence: {confidence}%\", fontsize=10)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf412bc",
   "metadata": {},
   "source": [
    "# Performance Metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09793960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0940dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Evaluate the model\n",
    "test_loss, test_accuracy = best_model.evaluate(test_dataset)\n",
    "print(\"Test Accuracy:\", round(test_accuracy * 100, 2), \"%\")\n",
    "\n",
    "# 2. Collect predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "    preds = best_model.predict(images, verbose=0)\n",
    "    predicted_classes = np.argmax(preds, axis=1)\n",
    "\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(predicted_classes)\n",
    "\n",
    "# 3. Classification Report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "# 4. Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names,\n",
    "            yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b5bba5",
   "metadata": {},
   "source": [
    "## Collecting prediction probabilities from best_model on the entire test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947ce85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs = []\n",
    "\n",
    "for images, _ in test_dataset:\n",
    "    probs = best_model.predict(images, verbose=0)\n",
    "    y_pred_probs.extend(probs)\n",
    "\n",
    "y_pred_probs = np.array(y_pred_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcdf32f",
   "metadata": {},
   "source": [
    "## ROC-AUC Curve (Multiclass OvR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aae367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "n_classes = y_pred_probs.shape[1]\n",
    "y_true_binarized = label_binarize(y_true, classes=list(range(n_classes)))\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], y_pred_probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'{class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"../results/metrices/TransferLearning/Transfer_Learning_roc_curve.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0f401f",
   "metadata": {},
   "source": [
    "## Precission-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974808dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 1. Generate prediction probabilities from the fine-tuned best model\n",
    "y_pred_probs = []\n",
    "\n",
    "for images, _ in test_dataset:\n",
    "    probs = best_model.predict(images, verbose=0)\n",
    "    y_pred_probs.extend(probs)\n",
    "\n",
    "y_pred_probs = np.array(y_pred_probs)\n",
    "\n",
    "# 2. Binarize true labels\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "n_classes = y_pred_probs.shape[1]\n",
    "y_true_binarized = label_binarize(y_true, classes=list(range(n_classes)))\n",
    "\n",
    "# 3. Plot Precision-Recall Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for i in range(n_classes):\n",
    "    precision, recall, _ = precision_recall_curve(y_true_binarized[:, i], y_pred_probs[:, i])\n",
    "    ap = average_precision_score(y_true_binarized[:, i], y_pred_probs[:, i])\n",
    "    plt.plot(recall, precision, label=f'{class_names[i]} (AP = {ap:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Multiclass Precision-Recall Curve (Fine-Tuned Model)')\n",
    "plt.legend(loc='lower left')\n",
    "plt.grid(True)\n",
    "\n",
    "# 4. Save the plot\n",
    "plt.savefig(\"../results/metrices/TransferLearning/Transfer_Learning_precision_recall_curve.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb3c20e",
   "metadata": {},
   "source": [
    "## F1-score vs. Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c096ea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Select the class index you want to analyze (e.g., 0 for the first class)\n",
    "class_index = 0\n",
    "class_name = class_names[class_index]  # Get readable class name\n",
    "\n",
    "# Thresholds to evaluate\n",
    "thresholds = np.linspace(0, 1, 100)\n",
    "f1s = []\n",
    "\n",
    "# Loop through thresholds to compute F1 scores\n",
    "for thresh in thresholds:\n",
    "    preds_thresh = (y_pred_probs[:, class_index] >= thresh).astype(int)\n",
    "    f1 = f1_score(y_true_binarized[:, class_index], preds_thresh)\n",
    "    f1s.append(f1)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(thresholds, f1s, color='purple')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title(f'F1 Score vs Threshold ({class_name})')\n",
    "plt.grid(True)\n",
    "\n",
    "# Save and show the plot\n",
    "plt.savefig(f\"../results/metrices/TransferLearning/Transfer_Learning_CNN_f1_score_vs_threshold_{class_name}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f190f8d2",
   "metadata": {},
   "source": [
    "## Save Final Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(f\"../models/{best_model_name}_(Transfer_Learning)_fine_tuned_model.keras\")\n",
    "print(f\"Model saved as: {best_model_name}_(Transfer_Learning)_fine_tuned_model.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".fish-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
